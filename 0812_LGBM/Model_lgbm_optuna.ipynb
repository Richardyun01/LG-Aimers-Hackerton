{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\syyun\\Desktop\\Programming\\Hackerton\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train shape: (102676, 3) | Unique items: 193\n",
      "Built train table shape: (675500, 29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 10:42:03,266] A new study created in memory with name: no-name-21aca522-1a6b-4ebc-b67e-a55b18fee6e6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Optuna hyperparameter optimization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 7.96215:   2%|▏         | 1/50 [04:47<3:55:09, 287.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 10:46:51,225] Trial 0 finished with value: 7.962150853893045 and parameters: {'learning_rate': 0.06621136956531415, 'num_leaves': 24, 'subsample': 0.8873189447938439, 'feature_fraction': 0.8150903015688392, 'min_child_samples': 32, 'lambda_l1': 1.5128854922100498e-07, 'lambda_l2': 1.272932553989984e-08}. Best is trial 0 with value: 7.962150853893045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 7.88574:   4%|▍         | 2/50 [08:07<3:08:45, 235.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 10:50:10,734] Trial 1 finished with value: 7.885743358007483 and parameters: {'learning_rate': 0.02919878625487737, 'num_leaves': 132, 'subsample': 0.7345141255524583, 'feature_fraction': 0.7545188331557351, 'min_child_samples': 45, 'lambda_l1': 0.01503010028045771, 'lambda_l2': 7.121537791676946e-06}. Best is trial 1 with value: 7.885743358007483.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 7.88574:   6%|▌         | 3/50 [10:29<2:31:08, 192.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 10:52:32,515] Trial 2 finished with value: 8.027736581114974 and parameters: {'learning_rate': 0.01666322539338427, 'num_leaves': 110, 'subsample': 0.653554196474395, 'feature_fraction': 0.6805286166966976, 'min_child_samples': 63, 'lambda_l1': 0.07269112345593329, 'lambda_l2': 1.7995413761178548e-05}. Best is trial 1 with value: 7.885743358007483.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 7.88574:   8%|▊         | 4/50 [13:52<2:30:54, 196.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 10:55:55,342] Trial 3 finished with value: 8.148407239240013 and parameters: {'learning_rate': 0.03394261141183528, 'num_leaves': 38, 'subsample': 0.6655230912060761, 'feature_fraction': 0.6740849767713605, 'min_child_samples': 63, 'lambda_l1': 0.029164897536005343, 'lambda_l2': 0.04746812993246654}. Best is trial 1 with value: 7.885743358007483.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 7.88574:  10%|█         | 5/50 [17:07<2:27:18, 196.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 10:59:11,023] Trial 4 finished with value: 7.995129765729204 and parameters: {'learning_rate': 0.057147486987636414, 'num_leaves': 115, 'subsample': 0.7769174137109995, 'feature_fraction': 0.9339290375832168, 'min_child_samples': 34, 'lambda_l1': 2.4659732513388477e-06, 'lambda_l2': 6.66624172089156e-08}. Best is trial 1 with value: 7.885743358007483.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 7.87419:  12%|█▏        | 6/50 [21:20<2:38:02, 215.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 11:03:23,559] Trial 5 finished with value: 7.874191064972437 and parameters: {'learning_rate': 0.012125284859295787, 'num_leaves': 132, 'subsample': 0.6486048376550102, 'feature_fraction': 0.6970446259367681, 'min_child_samples': 29, 'lambda_l1': 1.2880883386524115e-08, 'lambda_l2': 1.2205180482206484e-05}. Best is trial 5 with value: 7.874191064972437.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 7.79976:  14%|█▍        | 7/50 [24:32<2:28:52, 207.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 11:06:35,277] Trial 6 finished with value: 7.799759918296764 and parameters: {'learning_rate': 0.05487474854424262, 'num_leaves': 91, 'subsample': 0.8003998909526417, 'feature_fraction': 0.648683233858291, 'min_child_samples': 74, 'lambda_l1': 3.234725415242821e-07, 'lambda_l2': 1.8179951625940276e-06}. Best is trial 6 with value: 7.799759918296764.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 7.79976:  16%|█▌        | 8/50 [27:49<2:23:07, 204.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 11:09:52,784] Trial 7 finished with value: 7.941917450901276 and parameters: {'learning_rate': 0.08767034170917422, 'num_leaves': 64, 'subsample': 0.85196171202257, 'feature_fraction': 0.8273772007932451, 'min_child_samples': 71, 'lambda_l1': 0.12739218508421526, 'lambda_l2': 8.189260850141037e-07}. Best is trial 6 with value: 7.799759918296764.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 7.79976:  18%|█▊        | 9/50 [30:22<2:08:38, 188.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 11:12:25,362] Trial 8 finished with value: 8.447448014661829 and parameters: {'learning_rate': 0.01358549283701696, 'num_leaves': 27, 'subsample': 0.6230571058098512, 'feature_fraction': 0.8978397870914554, 'min_child_samples': 47, 'lambda_l1': 0.00015453235760667634, 'lambda_l2': 9.096821249486364e-07}. Best is trial 6 with value: 7.799759918296764.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 7.79976:  20%|██        | 10/50 [31:39<1:42:39, 153.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 11:13:42,639] Trial 9 finished with value: 8.035252160327193 and parameters: {'learning_rate': 0.0721751119991941, 'num_leaves': 73, 'subsample': 0.6917731153832645, 'feature_fraction': 0.8883809635315905, 'min_child_samples': 21, 'lambda_l1': 0.008887563261947338, 'lambda_l2': 0.00011115130178082463}. Best is trial 6 with value: 7.799759918296764.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 7.79976:  22%|██▏       | 11/50 [33:46<1:34:48, 145.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 11:15:50,039] Trial 10 finished with value: 8.032174129125842 and parameters: {'learning_rate': 0.04080875313451729, 'num_leaves': 95, 'subsample': 0.8138869759317549, 'feature_fraction': 0.6012731340998063, 'min_child_samples': 96, 'lambda_l1': 2.408167769110593e-05, 'lambda_l2': 0.013174496532365602}. Best is trial 6 with value: 7.799759918296764.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 7.69138:  24%|██▍       | 12/50 [38:50<2:02:49, 193.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 11:20:53,984] Trial 11 finished with value: 7.691379237904968 and parameters: {'learning_rate': 0.023809849555039373, 'num_leaves': 146, 'subsample': 0.7336167507737112, 'feature_fraction': 0.6843184361367838, 'min_child_samples': 83, 'lambda_l1': 1.0835845616344974e-08, 'lambda_l2': 0.0011198792989133475}. Best is trial 11 with value: 7.691379237904968.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 7.69138:  26%|██▌       | 13/50 [43:15<2:12:50, 215.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 11:25:18,811] Trial 12 finished with value: 7.692068407123103 and parameters: {'learning_rate': 0.020665366865884716, 'num_leaves': 145, 'subsample': 0.9475452953279875, 'feature_fraction': 0.6093036244677822, 'min_child_samples': 83, 'lambda_l1': 2.2932989728790858e-08, 'lambda_l2': 8.535647724517396}. Best is trial 11 with value: 7.691379237904968.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 7.68745:  28%|██▊       | 14/50 [47:59<2:21:44, 236.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 11:30:03,160] Trial 13 finished with value: 7.687446013231587 and parameters: {'learning_rate': 0.020231983390598004, 'num_leaves': 149, 'subsample': 0.9384025886496978, 'feature_fraction': 0.6060172054803832, 'min_child_samples': 92, 'lambda_l1': 5.589116505284597, 'lambda_l2': 4.093613601271157}. Best is trial 13 with value: 7.687446013231587.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 7.68745:  30%|███       | 15/50 [51:15<2:10:41, 224.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 11:33:18,922] Trial 14 finished with value: 7.745675442602222 and parameters: {'learning_rate': 0.022849309257008604, 'num_leaves': 148, 'subsample': 0.7261425751519693, 'feature_fraction': 0.7433167785536066, 'min_child_samples': 98, 'lambda_l1': 7.032055817331084, 'lambda_l2': 5.611054469163515}. Best is trial 13 with value: 7.687446013231587.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 7.68745:  32%|███▏      | 16/50 [55:02<2:07:20, 224.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 11:37:05,272] Trial 15 finished with value: 7.9585610531984345 and parameters: {'learning_rate': 0.010013153510034218, 'num_leaves': 119, 'subsample': 0.9437345370879463, 'feature_fraction': 0.7219125090004216, 'min_child_samples': 86, 'lambda_l1': 3.627635503593777, 'lambda_l2': 0.005198478821055681}. Best is trial 13 with value: 7.687446013231587.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 7.68745:  34%|███▍      | 17/50 [59:09<2:07:26, 231.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 11:41:13,163] Trial 16 finished with value: 7.8481204192541565 and parameters: {'learning_rate': 0.021645285385047827, 'num_leaves': 130, 'subsample': 0.8618655135140187, 'feature_fraction': 0.63643792378551, 'min_child_samples': 85, 'lambda_l1': 0.000945680442223218, 'lambda_l2': 0.3712961021424893}. Best is trial 13 with value: 7.687446013231587.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 7.68745:  36%|███▌      | 18/50 [1:02:06<1:54:48, 215.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 11:44:10,203] Trial 17 finished with value: 7.862617468300884 and parameters: {'learning_rate': 0.028817141475925897, 'num_leaves': 149, 'subsample': 0.7296828239614731, 'feature_fraction': 0.8024211551909924, 'min_child_samples': 91, 'lambda_l1': 1.0117193424838361e-05, 'lambda_l2': 0.002736415936330942}. Best is trial 13 with value: 7.687446013231587.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 7.68745:  38%|███▊      | 19/50 [1:06:30<1:58:40, 229.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 11:48:33,532] Trial 18 finished with value: 7.979767267988919 and parameters: {'learning_rate': 0.016942411140564856, 'num_leaves': 103, 'subsample': 0.9105922335319244, 'feature_fraction': 0.6403058222483263, 'min_child_samples': 76, 'lambda_l1': 0.6347053192982931, 'lambda_l2': 0.0006286716809115222}. Best is trial 13 with value: 7.687446013231587.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 7.68745:  40%|████      | 20/50 [1:11:09<2:02:12, 244.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 11:53:12,256] Trial 19 finished with value: 7.955718717566825 and parameters: {'learning_rate': 0.03782934711729321, 'num_leaves': 72, 'subsample': 0.8216177804089483, 'feature_fraction': 0.7134348919657092, 'min_child_samples': 54, 'lambda_l1': 0.0009755227989571566, 'lambda_l2': 0.23241386792938504}. Best is trial 13 with value: 7.687446013231587.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 7.68745:  42%|████▏     | 21/50 [1:17:52<2:21:14, 292.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 11:59:55,909] Trial 20 finished with value: 7.984912413151829 and parameters: {'learning_rate': 0.025224425161308767, 'num_leaves': 52, 'subsample': 0.770482120963532, 'feature_fraction': 0.667084601190153, 'min_child_samples': 100, 'lambda_l1': 0.00010035007606144786, 'lambda_l2': 0.8921141899748837}. Best is trial 13 with value: 7.687446013231587.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 7.68745:  44%|████▍     | 22/50 [1:22:04<2:10:44, 280.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 12:04:08,008] Trial 21 finished with value: 7.764665075054209 and parameters: {'learning_rate': 0.017170379561654764, 'num_leaves': 139, 'subsample': 0.9441690967587151, 'feature_fraction': 0.6046196527161464, 'min_child_samples': 83, 'lambda_l1': 4.488405277901734e-08, 'lambda_l2': 8.038775220990008}. Best is trial 13 with value: 7.687446013231587.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 7.68745:  46%|████▌     | 23/50 [1:24:33<1:48:18, 240.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 12:06:36,572] Trial 22 finished with value: 7.945265009760791 and parameters: {'learning_rate': 0.019786369258406225, 'num_leaves': 148, 'subsample': 0.9091557611842787, 'feature_fraction': 0.621988047973905, 'min_child_samples': 80, 'lambda_l1': 6.888782024572166e-07, 'lambda_l2': 1.6981969186189174}. Best is trial 13 with value: 7.687446013231587.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 7.68745:  48%|████▊     | 24/50 [1:29:08<1:48:48, 251.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 12:11:11,995] Trial 23 finished with value: 7.869866442032682 and parameters: {'learning_rate': 0.025902294981587127, 'num_leaves': 120, 'subsample': 0.9120794577704301, 'feature_fraction': 0.6018333363500336, 'min_child_samples': 91, 'lambda_l1': 1.68991747452858e-08, 'lambda_l2': 0.05694531538409631}. Best is trial 13 with value: 7.687446013231587.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 7.68745:  50%|█████     | 25/50 [1:31:52<1:33:42, 224.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 12:13:55,737] Trial 24 finished with value: 7.941805867821603 and parameters: {'learning_rate': 0.013986169981585002, 'num_leaves': 137, 'subsample': 0.8626782299512005, 'feature_fraction': 0.6439143254261005, 'min_child_samples': 71, 'lambda_l1': 7.983696151623501e-08, 'lambda_l2': 0.0873564758579071}. Best is trial 13 with value: 7.687446013231587.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 7.68745:  52%|█████▏    | 26/50 [1:35:57<1:32:19, 230.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 12:18:00,376] Trial 25 finished with value: 7.823803090555014 and parameters: {'learning_rate': 0.01993843161051089, 'num_leaves': 123, 'subsample': 0.9497060059612892, 'feature_fraction': 0.6649757015163602, 'min_child_samples': 92, 'lambda_l1': 1.4986981157843932e-06, 'lambda_l2': 2.182553102367862}. Best is trial 13 with value: 7.687446013231587.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 7.68745:  54%|█████▍    | 27/50 [1:37:00<1:09:13, 180.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 12:19:03,750] Trial 26 finished with value: 7.957014496885524 and parameters: {'learning_rate': 0.045558952575710236, 'num_leaves': 140, 'subsample': 0.7557298051767014, 'feature_fraction': 0.7039648271848966, 'min_child_samples': 79, 'lambda_l1': 6.4412278607036854e-06, 'lambda_l2': 0.0002849065438685182}. Best is trial 13 with value: 7.687446013231587.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 7.68745:  56%|█████▌    | 28/50 [1:38:38<57:08, 155.85s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 12:20:41,909] Trial 27 finished with value: 7.792399841930424 and parameters: {'learning_rate': 0.03328447287685018, 'num_leaves': 150, 'subsample': 0.7028063770718556, 'feature_fraction': 0.6238089904229009, 'min_child_samples': 69, 'lambda_l1': 1.186261049165368e-08, 'lambda_l2': 9.392017326786078}. Best is trial 13 with value: 7.687446013231587.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 7.68745:  58%|█████▊    | 29/50 [1:42:41<1:03:38, 181.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 12:24:44,295] Trial 28 finished with value: 8.007321852656943 and parameters: {'learning_rate': 0.024358666081250886, 'num_leaves': 101, 'subsample': 0.8374392588369127, 'feature_fraction': 0.7754998054069564, 'min_child_samples': 88, 'lambda_l1': 0.004660671886874479, 'lambda_l2': 0.016099448225912683}. Best is trial 13 with value: 7.687446013231587.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 7.68745:  60%|██████    | 30/50 [1:46:37<1:06:04, 198.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 12:28:40,881] Trial 29 finished with value: 7.767961193309805 and parameters: {'learning_rate': 0.01908503466450682, 'num_leaves': 127, 'subsample': 0.8861420383645422, 'feature_fraction': 0.6849363824206314, 'min_child_samples': 58, 'lambda_l1': 1.2185108634161317e-07, 'lambda_l2': 4.127378069521915e-08}. Best is trial 13 with value: 7.687446013231587.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 7.68745:  62%|██████▏   | 31/50 [1:49:53<1:02:30, 197.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 12:31:56,304] Trial 30 finished with value: 7.972634107226844 and parameters: {'learning_rate': 0.015822837716518254, 'num_leaves': 139, 'subsample': 0.8868171441587113, 'feature_fraction': 0.7285614208739972, 'min_child_samples': 80, 'lambda_l1': 2.764949153605038e-07, 'lambda_l2': 0.6221972068262127}. Best is trial 13 with value: 7.687446013231587.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 7.61356:  64%|██████▍   | 32/50 [1:54:54<1:08:37, 228.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 12:36:58,119] Trial 31 finished with value: 7.613556290419443 and parameters: {'learning_rate': 0.02223107357910896, 'num_leaves': 143, 'subsample': 0.6997533428396597, 'feature_fraction': 0.7656843584182942, 'min_child_samples': 100, 'lambda_l1': 6.7614576606843055, 'lambda_l2': 5.4694159958898325}. Best is trial 31 with value: 7.613556290419443.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 7.61356:  66%|██████▌   | 33/50 [1:57:47<1:00:01, 211.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 12:39:50,601] Trial 32 finished with value: 7.710264171922859 and parameters: {'learning_rate': 0.027006150349191894, 'num_leaves': 143, 'subsample': 0.6956919316620395, 'feature_fraction': 0.7692749122198306, 'min_child_samples': 94, 'lambda_l1': 0.39269028346114865, 'lambda_l2': 3.090656803627626}. Best is trial 31 with value: 7.613556290419443.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 7.61356:  68%|██████▊   | 34/50 [1:59:12<46:20, 173.77s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 12:41:15,484] Trial 33 finished with value: 8.065196303132772 and parameters: {'learning_rate': 0.021859687678114668, 'num_leaves': 131, 'subsample': 0.7494596833694526, 'feature_fraction': 0.8463260513776409, 'min_child_samples': 100, 'lambda_l1': 1.7833456534589822, 'lambda_l2': 0.16594933553179803}. Best is trial 31 with value: 7.613556290419443.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 7.61356:  70%|███████   | 35/50 [2:00:51<37:50, 151.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 12:42:54,688] Trial 34 finished with value: 7.958640848288186 and parameters: {'learning_rate': 0.030013530099209765, 'num_leaves': 109, 'subsample': 0.6740430502513663, 'feature_fraction': 0.6597771964033915, 'min_child_samples': 87, 'lambda_l1': 1.351904075705446, 'lambda_l2': 0.7864055410368859}. Best is trial 31 with value: 7.613556290419443.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 7.61356:  72%|███████▏  | 36/50 [2:03:38<36:23, 156.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 12:45:41,430] Trial 35 finished with value: 7.940917580908178 and parameters: {'learning_rate': 0.015023725175787053, 'num_leaves': 135, 'subsample': 0.7908965353631767, 'feature_fraction': 0.7966189505260894, 'min_child_samples': 93, 'lambda_l1': 0.1627380130106792, 'lambda_l2': 3.2609803456179516}. Best is trial 31 with value: 7.613556290419443.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 7.61356:  74%|███████▍  | 37/50 [2:05:59<32:50, 151.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 12:48:02,588] Trial 36 finished with value: 8.00237902593303 and parameters: {'learning_rate': 0.01863892715950787, 'num_leaves': 125, 'subsample': 0.6190581315981297, 'feature_fraction': 0.6882490188311975, 'min_child_samples': 82, 'lambda_l1': 3.869266718595977e-08, 'lambda_l2': 0.019713947947941218}. Best is trial 31 with value: 7.613556290419443.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 7.61356:  76%|███████▌  | 38/50 [2:12:53<46:04, 230.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 12:54:56,812] Trial 37 finished with value: 7.735883598512342 and parameters: {'learning_rate': 0.012094186494612424, 'num_leaves': 144, 'subsample': 0.7119853081955537, 'feature_fraction': 0.6226601236620363, 'min_child_samples': 66, 'lambda_l1': 8.630610379080471, 'lambda_l2': 7.756251546830736e-05}. Best is trial 31 with value: 7.613556290419443.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 7.61356:  78%|███████▊  | 39/50 [2:16:27<41:20, 225.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 12:58:31,126] Trial 38 finished with value: 7.842430573317972 and parameters: {'learning_rate': 0.03351589746170499, 'num_leaves': 114, 'subsample': 0.9255514076022492, 'feature_fraction': 0.7516847064228314, 'min_child_samples': 76, 'lambda_l1': 0.0016780722589111762, 'lambda_l2': 0.0016201120685377136}. Best is trial 31 with value: 7.613556290419443.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 7.61356:  80%|████████  | 40/50 [2:18:56<33:45, 202.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 13:01:00,100] Trial 39 finished with value: 7.973230707237901 and parameters: {'learning_rate': 0.02240873425176343, 'num_leaves': 133, 'subsample': 0.6400486745608654, 'feature_fraction': 0.856054786531521, 'min_child_samples': 89, 'lambda_l1': 0.025194255763124923, 'lambda_l2': 2.8914208752192396e-06}. Best is trial 31 with value: 7.613556290419443.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 7.61356:  82%|████████▏ | 41/50 [2:22:18<30:20, 202.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 13:04:21,659] Trial 40 finished with value: 7.765868463722143 and parameters: {'learning_rate': 0.029084612026232592, 'num_leaves': 142, 'subsample': 0.6003549895082109, 'feature_fraction': 0.7367436871540513, 'min_child_samples': 40, 'lambda_l1': 0.08441020702590175, 'lambda_l2': 1.481766651523264e-07}. Best is trial 31 with value: 7.613556290419443.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 7.61356:  84%|████████▍ | 42/50 [2:24:40<24:32, 184.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 13:06:43,330] Trial 41 finished with value: 7.823351546066359 and parameters: {'learning_rate': 0.026689937361619235, 'num_leaves': 144, 'subsample': 0.6755454402375283, 'feature_fraction': 0.7656938897728007, 'min_child_samples': 96, 'lambda_l1': 0.4365084077702627, 'lambda_l2': 2.044775362027629}. Best is trial 31 with value: 7.613556290419443.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 7.61356:  86%|████████▌ | 43/50 [2:29:34<25:19, 217.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 13:11:37,591] Trial 42 finished with value: 7.6252870877352334 and parameters: {'learning_rate': 0.01782247084536294, 'num_leaves': 150, 'subsample': 0.7146741094498099, 'feature_fraction': 0.7817936741628383, 'min_child_samples': 95, 'lambda_l1': 0.3527053604418304, 'lambda_l2': 9.523799546394795}. Best is trial 31 with value: 7.613556290419443.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 7.61356:  88%|████████▊ | 44/50 [2:35:04<25:06, 251.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 13:17:08,119] Trial 43 finished with value: 7.672952405962045 and parameters: {'learning_rate': 0.017688295817634432, 'num_leaves': 149, 'subsample': 0.7172921753088428, 'feature_fraction': 0.7999932258761216, 'min_child_samples': 97, 'lambda_l1': 2.4370337155311597, 'lambda_l2': 9.127726536571322}. Best is trial 31 with value: 7.613556290419443.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 7.61356:  90%|█████████ | 45/50 [2:38:55<20:25, 245.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 13:20:59,088] Trial 44 finished with value: 7.775203280405412 and parameters: {'learning_rate': 0.01764478541932194, 'num_leaves': 150, 'subsample': 0.745786333150523, 'feature_fraction': 0.7907752841019572, 'min_child_samples': 96, 'lambda_l1': 2.1689651409710415, 'lambda_l2': 1.0878863507000023}. Best is trial 31 with value: 7.613556290419443.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 7.61356:  92%|█████████▏| 46/50 [2:47:34<21:49, 327.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 13:29:38,034] Trial 45 finished with value: 7.881202800759581 and parameters: {'learning_rate': 0.012727667142462705, 'num_leaves': 84, 'subsample': 0.7153247679208768, 'feature_fraction': 0.8375827278488442, 'min_child_samples': 100, 'lambda_l1': 0.8227586067402539, 'lambda_l2': 0.12199970658244201}. Best is trial 31 with value: 7.613556290419443.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 7.61356:  94%|█████████▍| 47/50 [2:53:48<17:03, 341.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 13:35:51,577] Trial 46 finished with value: 7.742085143359112 and parameters: {'learning_rate': 0.015369397019242913, 'num_leaves': 135, 'subsample': 0.7698837590392087, 'feature_fraction': 0.8186261845079228, 'min_child_samples': 95, 'lambda_l1': 4.663509122726009, 'lambda_l2': 0.3388777546116026}. Best is trial 31 with value: 7.613556290419443.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 7.61356:  96%|█████████▌| 48/50 [2:57:31<10:11, 305.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 13:39:34,628] Trial 47 finished with value: 7.710952299582631 and parameters: {'learning_rate': 0.02401508718471817, 'num_leaves': 126, 'subsample': 0.6808227877827572, 'feature_fraction': 0.8714930706184081, 'min_child_samples': 89, 'lambda_l1': 9.776415460459217, 'lambda_l2': 4.412317340855583}. Best is trial 31 with value: 7.613556290419443.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 7.61356:  98%|█████████▊| 49/50 [2:58:22<03:49, 229.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 13:40:25,564] Trial 48 finished with value: 8.09454791176935 and parameters: {'learning_rate': 0.09652930056017227, 'num_leaves': 41, 'subsample': 0.654215733025122, 'feature_fraction': 0.9194089062674167, 'min_child_samples': 97, 'lambda_l1': 0.24070876483290632, 'lambda_l2': 8.155771548456004}. Best is trial 31 with value: 7.613556290419443.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 7.61356: 100%|██████████| 50/50 [3:06:32<00:00, 223.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 13:48:35,788] Trial 49 finished with value: 7.753789190179663 and parameters: {'learning_rate': 0.010347704964471226, 'num_leaves': 132, 'subsample': 0.7294567249657544, 'feature_fraction': 0.780202247407111, 'min_child_samples': 86, 'lambda_l1': 0.05546435929752246, 'lambda_l2': 0.43711410325308503}. Best is trial 31 with value: 7.613556290419443.\n",
      "\n",
      "==================================================\n",
      "Optuna Optimization Finished!\n",
      "Best trial's Weighted SMAPE: 7.613556290419443\n",
      "Best hyperparameters: {'learning_rate': 0.02223107357910896, 'num_leaves': 143, 'subsample': 0.6997533428396597, 'feature_fraction': 0.7656843584182942, 'min_child_samples': 100, 'lambda_l1': 6.7614576606843055, 'lambda_l2': 5.4694159958898325}\n",
      "==================================================\n",
      "\n",
      "Training the final model with the best hyperparameters...\n",
      "Final Valid SMAPE (Original): 132.6214\n",
      "Final Valid SMAPE (Competition Weighted): 5.819903\n",
      "\n",
      "Final model and feature list saved.\n",
      "Generating submission file...\n",
      "\n",
      "Submission file created successfully -> submission_optuna.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>영업일자</th>\n",
       "      <th>느티나무 셀프BBQ_1인 수저세트</th>\n",
       "      <th>느티나무 셀프BBQ_BBQ55(단체)</th>\n",
       "      <th>느티나무 셀프BBQ_대여료 30,000원</th>\n",
       "      <th>느티나무 셀프BBQ_대여료 60,000원</th>\n",
       "      <th>느티나무 셀프BBQ_대여료 90,000원</th>\n",
       "      <th>느티나무 셀프BBQ_본삼겹 (단품,실내)</th>\n",
       "      <th>느티나무 셀프BBQ_스프라이트 (단체)</th>\n",
       "      <th>느티나무 셀프BBQ_신라면</th>\n",
       "      <th>느티나무 셀프BBQ_쌈야채세트</th>\n",
       "      <th>...</th>\n",
       "      <th>화담숲주막_스프라이트</th>\n",
       "      <th>화담숲주막_참살이 막걸리</th>\n",
       "      <th>화담숲주막_찹쌀식혜</th>\n",
       "      <th>화담숲주막_콜라</th>\n",
       "      <th>화담숲주막_해물파전</th>\n",
       "      <th>화담숲카페_메밀미숫가루</th>\n",
       "      <th>화담숲카페_아메리카노 HOT</th>\n",
       "      <th>화담숲카페_아메리카노 ICE</th>\n",
       "      <th>화담숲카페_카페라떼 ICE</th>\n",
       "      <th>화담숲카페_현미뻥스크림</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00+1일</td>\n",
       "      <td>5.614698</td>\n",
       "      <td>7.051601</td>\n",
       "      <td>4.215854</td>\n",
       "      <td>3.712702</td>\n",
       "      <td>0.489786</td>\n",
       "      <td>1.200534</td>\n",
       "      <td>1.642430</td>\n",
       "      <td>2.775638</td>\n",
       "      <td>2.430695</td>\n",
       "      <td>...</td>\n",
       "      <td>8.215223</td>\n",
       "      <td>21.438593</td>\n",
       "      <td>19.012745</td>\n",
       "      <td>9.388106</td>\n",
       "      <td>44.124607</td>\n",
       "      <td>37.022834</td>\n",
       "      <td>6.166973</td>\n",
       "      <td>30.672032</td>\n",
       "      <td>9.355602</td>\n",
       "      <td>18.145919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00+2일</td>\n",
       "      <td>2.921619</td>\n",
       "      <td>4.610685</td>\n",
       "      <td>1.985845</td>\n",
       "      <td>1.726812</td>\n",
       "      <td>0.089844</td>\n",
       "      <td>0.487418</td>\n",
       "      <td>3.505720</td>\n",
       "      <td>1.508797</td>\n",
       "      <td>1.167092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266943</td>\n",
       "      <td>2.360555</td>\n",
       "      <td>2.028825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.606676</td>\n",
       "      <td>2.513820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.608939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00+3일</td>\n",
       "      <td>3.764345</td>\n",
       "      <td>10.295247</td>\n",
       "      <td>2.431092</td>\n",
       "      <td>2.030662</td>\n",
       "      <td>0.456175</td>\n",
       "      <td>0.851525</td>\n",
       "      <td>5.819088</td>\n",
       "      <td>1.789391</td>\n",
       "      <td>1.489997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973836</td>\n",
       "      <td>7.934783</td>\n",
       "      <td>7.552458</td>\n",
       "      <td>0.892002</td>\n",
       "      <td>23.717235</td>\n",
       "      <td>20.311741</td>\n",
       "      <td>2.693818</td>\n",
       "      <td>26.085880</td>\n",
       "      <td>5.523975</td>\n",
       "      <td>11.159912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00+4일</td>\n",
       "      <td>4.010242</td>\n",
       "      <td>15.392397</td>\n",
       "      <td>2.409802</td>\n",
       "      <td>2.097987</td>\n",
       "      <td>0.477158</td>\n",
       "      <td>0.870695</td>\n",
       "      <td>5.436389</td>\n",
       "      <td>1.808561</td>\n",
       "      <td>1.533672</td>\n",
       "      <td>...</td>\n",
       "      <td>1.122577</td>\n",
       "      <td>7.895230</td>\n",
       "      <td>7.660190</td>\n",
       "      <td>0.958656</td>\n",
       "      <td>21.939712</td>\n",
       "      <td>15.248174</td>\n",
       "      <td>1.543787</td>\n",
       "      <td>18.847910</td>\n",
       "      <td>3.915985</td>\n",
       "      <td>9.080520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00+5일</td>\n",
       "      <td>6.695717</td>\n",
       "      <td>49.871573</td>\n",
       "      <td>3.765098</td>\n",
       "      <td>3.147017</td>\n",
       "      <td>0.788555</td>\n",
       "      <td>1.238716</td>\n",
       "      <td>12.153636</td>\n",
       "      <td>2.485572</td>\n",
       "      <td>1.998570</td>\n",
       "      <td>...</td>\n",
       "      <td>2.388276</td>\n",
       "      <td>10.737758</td>\n",
       "      <td>10.275491</td>\n",
       "      <td>2.459643</td>\n",
       "      <td>28.021674</td>\n",
       "      <td>22.077062</td>\n",
       "      <td>2.674417</td>\n",
       "      <td>25.186979</td>\n",
       "      <td>5.926742</td>\n",
       "      <td>11.008191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         영업일자  느티나무 셀프BBQ_1인 수저세트  느티나무 셀프BBQ_BBQ55(단체)  \\\n",
       "0  TEST_00+1일            5.614698              7.051601   \n",
       "1  TEST_00+2일            2.921619              4.610685   \n",
       "2  TEST_00+3일            3.764345             10.295247   \n",
       "3  TEST_00+4일            4.010242             15.392397   \n",
       "4  TEST_00+5일            6.695717             49.871573   \n",
       "\n",
       "   느티나무 셀프BBQ_대여료 30,000원  느티나무 셀프BBQ_대여료 60,000원  느티나무 셀프BBQ_대여료 90,000원  \\\n",
       "0                4.215854                3.712702                0.489786   \n",
       "1                1.985845                1.726812                0.089844   \n",
       "2                2.431092                2.030662                0.456175   \n",
       "3                2.409802                2.097987                0.477158   \n",
       "4                3.765098                3.147017                0.788555   \n",
       "\n",
       "   느티나무 셀프BBQ_본삼겹 (단품,실내)  느티나무 셀프BBQ_스프라이트 (단체)  느티나무 셀프BBQ_신라면  \\\n",
       "0                1.200534               1.642430        2.775638   \n",
       "1                0.487418               3.505720        1.508797   \n",
       "2                0.851525               5.819088        1.789391   \n",
       "3                0.870695               5.436389        1.808561   \n",
       "4                1.238716              12.153636        2.485572   \n",
       "\n",
       "   느티나무 셀프BBQ_쌈야채세트  ...  화담숲주막_스프라이트  화담숲주막_참살이 막걸리  화담숲주막_찹쌀식혜  화담숲주막_콜라  \\\n",
       "0          2.430695  ...     8.215223      21.438593   19.012745  9.388106   \n",
       "1          1.167092  ...     0.266943       2.360555    2.028825  0.000000   \n",
       "2          1.489997  ...     0.973836       7.934783    7.552458  0.892002   \n",
       "3          1.533672  ...     1.122577       7.895230    7.660190  0.958656   \n",
       "4          1.998570  ...     2.388276      10.737758   10.275491  2.459643   \n",
       "\n",
       "   화담숲주막_해물파전  화담숲카페_메밀미숫가루  화담숲카페_아메리카노 HOT  화담숲카페_아메리카노 ICE  화담숲카페_카페라떼 ICE  \\\n",
       "0   44.124607     37.022834         6.166973        30.672032        9.355602   \n",
       "1    1.606676      2.513820         0.000000         2.608939        0.000000   \n",
       "2   23.717235     20.311741         2.693818        26.085880        5.523975   \n",
       "3   21.939712     15.248174         1.543787        18.847910        3.915985   \n",
       "4   28.021674     22.077062         2.674417        25.186979        5.926742   \n",
       "\n",
       "   화담숲카페_현미뻥스크림  \n",
       "0     18.145919  \n",
       "1      0.009193  \n",
       "2     11.159912  \n",
       "3      9.080520  \n",
       "4     11.008191  \n",
       "\n",
       "[5 rows x 194 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =======================================================\n",
    "# Colab: LightGBM 7일 수요예측 (Optuna 최적화 포함) - ONE CELL\n",
    "# =======================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from lightgbm import LGBMRegressor, early_stopping\n",
    "import joblib\n",
    "\n",
    "# 2. 시드 고정 및 기본 설정\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# =======================================================\n",
    "# 3. 공통 함수 (피처 생성 및 평가)\n",
    "# =======================================================\n",
    "\n",
    "# 피처 엔지니어링 파라미터\n",
    "LAGS  = [1, 2, 3, 7, 14, 21, 28]\n",
    "ROLLS = [7, 14, 28]\n",
    "\n",
    "def smape(y_true, y_pred) -> float:\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    denom = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
    "    diff  = np.abs(y_true - y_pred)\n",
    "    denom[denom == 0] = 1.0\n",
    "    return float(np.mean(diff / denom) * 100.0)\n",
    "\n",
    "def build_train_table(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.sort_values(['영업장명_메뉴명','영업일자']).reset_index(drop=True)\n",
    "    df['item_le'] = df['영업장명_메뉴명'].astype('category').cat.codes\n",
    "\n",
    "    # Lags\n",
    "    for k in LAGS:\n",
    "        df[f'lag_{k}'] = df.groupby('영업장명_메뉴명')['매출수량'].shift(k)\n",
    "\n",
    "    # Rolling(누수 방지: 1일 시프트 후)\n",
    "    df['qty_shift1'] = df.groupby('영업장명_메뉴명')['매출수량'].shift(1)\n",
    "    for w in ROLLS:\n",
    "        df[f'roll_mean_{w}'] = (\n",
    "            df.groupby('영업장명_메뉴명')['qty_shift1']\n",
    "              .rolling(window=w, min_periods=w).mean()\n",
    "              .reset_index(level=0, drop=True)\n",
    "        )\n",
    "        df[f'roll_std_{w}']  = (\n",
    "            df.groupby('영업장명_메뉴명')['qty_shift1']\n",
    "              .rolling(window=w, min_periods=w).std()\n",
    "              .reset_index(level=0, drop=True)\n",
    "        )\n",
    "\n",
    "    df['roll_min_7'] = (\n",
    "        df.groupby('영업장명_메뉴명')['qty_shift1']\n",
    "          .rolling(window=7, min_periods=7).min()\n",
    "          .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    df['roll_max_7'] = (\n",
    "        df.groupby('영업장명_메뉴명')['qty_shift1']\n",
    "          .rolling(window=7, min_periods=7).max()\n",
    "          .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    df['roll_sum_7'] = (\n",
    "        df.groupby('영업장명_메뉴명')['qty_shift1']\n",
    "          .rolling(window=7, min_periods=7).sum()\n",
    "          .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    df['is_zero'] = (df['qty_shift1'] == 0).astype(float)\n",
    "    df['zero_ratio_28'] = (\n",
    "        df.groupby('영업장명_메뉴명')['is_zero']\n",
    "          .rolling(window=28, min_periods=28).mean()\n",
    "          .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    # 캘린더(참조일)\n",
    "    df['ref_year']       = df['영업일자'].dt.year\n",
    "    df['ref_month']      = df['영업일자'].dt.month\n",
    "    df['ref_day']        = df['영업일자'].dt.day\n",
    "    df['ref_weekday']    = df['영업일자'].dt.weekday\n",
    "    df['ref_is_weekend'] = df['ref_weekday'].isin([5,6]).astype(int)\n",
    "\n",
    "    # 타깃(1~7일 후)\n",
    "    for h in range(1, 8):\n",
    "        df[f'y_h{h}'] = df.groupby('영업장명_메뉴명')['매출수량'].shift(-h)\n",
    "\n",
    "    base_cols = (\n",
    "        ['영업장명_메뉴명','item_le','영업일자',\n",
    "         'ref_year','ref_month','ref_day','ref_weekday','ref_is_weekend']\n",
    "        + [f'lag_{k}' for k in LAGS]\n",
    "        + [f'roll_mean_{w}' for w in ROLLS]\n",
    "        + [f'roll_std_{w}'  for w in ROLLS]\n",
    "        + ['roll_min_7','roll_max_7','roll_sum_7','zero_ratio_28']\n",
    "    )\n",
    "\n",
    "    # long-format: h=1..7\n",
    "    records = []\n",
    "    for h in range(1, 8):\n",
    "        tmp = df[base_cols + [f'y_h{h}']].copy()\n",
    "        tmp = tmp.rename(columns={f'y_h{h}':'y'})\n",
    "        tmp['h'] = h\n",
    "        tmp['target_weekday']    = (df['영업일자'] + pd.to_timedelta(h, unit='D')).dt.weekday\n",
    "        tmp['target_is_weekend'] = tmp['target_weekday'].isin([5,6]).astype(int)\n",
    "        records.append(tmp)\n",
    "\n",
    "    Xy = pd.concat(records, axis=0, ignore_index=True)\n",
    "    Xy = Xy.rename(columns={'영업일자':'ref_date'})\n",
    "    Xy = Xy.dropna()\n",
    "    return Xy\n",
    "\n",
    "def build_test_features(test_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    test_df = test_df.sort_values(['영업장명_메뉴명','영업일자']).reset_index(drop=True)\n",
    "    test_df['item_le'] = test_df['영업장명_메뉴명'].astype('category').cat.codes\n",
    "\n",
    "    feats = []\n",
    "    for item, g in test_df.groupby('영업장명_메뉴명'):\n",
    "        g = g.sort_values('영업일자')\n",
    "        if len(g) < 28:\n",
    "            continue\n",
    "        last28 = g.tail(28).copy()\n",
    "        ref_date = last28['영업일자'].iloc[-1]\n",
    "        qty = last28['매출수량'].values.astype(float)\n",
    "\n",
    "        base = {\n",
    "            'item_le': int(last28['item_le'].iloc[-1]),\n",
    "            'ref_year': ref_date.year,\n",
    "            'ref_month': ref_date.month,\n",
    "            'ref_day': ref_date.day,\n",
    "            'ref_weekday': ref_date.weekday(),\n",
    "            'ref_is_weekend': 1 if ref_date.weekday() in (5,6) else 0,\n",
    "        }\n",
    "        for k in LAGS:\n",
    "            base[f'lag_{k}'] = float(qty[-k])\n",
    "        for w in ROLLS:\n",
    "            tail = qty[-w:]\n",
    "            base[f'roll_mean_{w}'] = float(np.mean(tail))\n",
    "            base[f'roll_std_{w}']  = float(np.std(tail, ddof=0))\n",
    "\n",
    "        base['roll_min_7'] = float(np.min(qty[-7:]))\n",
    "        base['roll_max_7'] = float(np.max(qty[-7:]))\n",
    "        base['roll_sum_7'] = float(np.sum(qty[-7:]))\n",
    "        base['zero_ratio_28'] = float(np.mean(qty == 0))\n",
    "\n",
    "        for h in range(1, 8):\n",
    "            row = base.copy()\n",
    "            t_wd = (ref_date + pd.Timedelta(days=h)).weekday()\n",
    "            row['h'] = h\n",
    "            row['target_weekday'] = t_wd\n",
    "            row['target_is_weekend'] = 1 if t_wd in (5,6) else 0\n",
    "            row['영업장명_메뉴명'] = item\n",
    "            feats.append(row)\n",
    "\n",
    "    return pd.DataFrame(feats)\n",
    "\n",
    "\n",
    "def calculate_weighted_smape(y_true: np.ndarray, y_pred: np.ndarray, df_info: pd.DataFrame, weights: dict = None) -> float:\n",
    "    temp_df = df_info.copy()\n",
    "    temp_df['actual'] = y_true\n",
    "    temp_df['prediction'] = np.maximum(0, y_pred)\n",
    "\n",
    "    total_score = 0\n",
    "    if weights is None:\n",
    "        unique_stores = temp_df['store'].unique()\n",
    "        weights = {s: 1.0 for s in unique_stores}\n",
    "\n",
    "    for s in temp_df['store'].unique():\n",
    "        store_df = temp_df[temp_df['store'] == s]\n",
    "        item_smapes = []\n",
    "        for i in store_df['item'].unique():\n",
    "            item_df = store_df[store_df['item'] == i]\n",
    "            valid_days_df = item_df[item_df['actual'] != 0].copy()\n",
    "            if len(valid_days_df) == 0:\n",
    "                item_smapes.append(0.0)\n",
    "                continue\n",
    "            diff = np.abs(valid_days_df['actual'] - valid_days_df['prediction'])\n",
    "            denom = np.abs(valid_days_df['actual']) + np.abs(valid_days_df['prediction'])\n",
    "            smape_i = np.mean(2 * diff / denom)\n",
    "            item_smapes.append(smape_i)\n",
    "        store_smape = np.mean(item_smapes)\n",
    "        ws = weights.get(s, 1.0)\n",
    "        total_score += ws * store_smape\n",
    "    return total_score\n",
    "\n",
    "\n",
    "# =======================================================\n",
    "# 4. 데이터 로드 및 전처리\n",
    "# =======================================================\n",
    "# 파일 업로드 확인\n",
    "required_files = [\"train.csv\", \"sample_submission.csv\"] + [f\"TEST_{i:02d}.csv\" for i in range(10)]\n",
    "for f in required_files:\n",
    "    if not os.path.exists(f):\n",
    "        raise FileNotFoundError(f\"필수 파일이 없습니다: {f}. Colab에 파일을 업로드해주세요.\")\n",
    "\n",
    "train = pd.read_csv(\"train.csv\", parse_dates=[\"영업일자\"])\n",
    "train = train.sort_values(['영업장명_메뉴명','영업일자'])\n",
    "print(\"Original train shape:\", train.shape, \"| Unique items:\", train['영업장명_메뉴명'].nunique())\n",
    "\n",
    "Xy = build_train_table(train)\n",
    "print(\"Built train table shape:\", Xy.shape)\n",
    "\n",
    "# =======================================================\n",
    "# 5. 가중치 설계\n",
    "# =======================================================\n",
    "Xy['w'] = 1.0\n",
    "rd = Xy['ref_date']\n",
    "\n",
    "# (A) 기간별 버킷 가중치\n",
    "Xy.loc[(rd >= '2023-01-01') & (rd <= '2023-12-31'), 'w'] = 0.9\n",
    "Xy.loc[(rd >= '2023-06-01') & (rd <= '2023-07-15'), 'w'] = 1.3 # 덮어쓰기\n",
    "Xy.loc[(rd >= '2024-01-01') & (rd <= '2024-04-30'), 'w'] = 1.0\n",
    "Xy.loc[(rd >= '2024-05-01') & (rd <= '2024-05-31'), 'w'] = 1.2\n",
    "Xy.loc[(rd >= '2024-06-01') & (rd <= '2024-06-15'), 'w'] = 1.4\n",
    "\n",
    "# (B) 동적 가중치: 시간 감쇠, 주말, 예측 시점\n",
    "HALF_LIFE_DAYS = 60\n",
    "days_from_max = (Xy['ref_date'].max() - rd).dt.days.clip(lower=0)\n",
    "decay = 0.5 ** (days_from_max / HALF_LIFE_DAYS)\n",
    "Xy['w'] *= decay\n",
    "Xy.loc[Xy['target_is_weekend'] == 1, 'w'] *= 1.10\n",
    "Xy['w'] *= (1.0 + (8 - Xy['h']) * 0.02)\n",
    "\n",
    "# =======================================================\n",
    "# 6. Optuna를 이용한 하이퍼파라미터 최적화\n",
    "# =======================================================\n",
    "VALID_DAYS      = 14\n",
    "N_ESTIMATORS    = 2000\n",
    "# Optuna 실행 시에는 early stopping을 짧게 주어 탐색 속도를 높이는 것이 효율적\n",
    "OPTUNA_EARLY_STOPPING = 50\n",
    "\n",
    "# 데이터 분할\n",
    "cutoff = Xy['ref_date'].max() - pd.Timedelta(days=VALID_DAYS)\n",
    "train_mask = Xy['ref_date'] <= cutoff\n",
    "valid_mask = Xy['ref_date'] >  cutoff\n",
    "\n",
    "feature_cols = [c for c in Xy.columns if c not in ['y','영업장명_메뉴명','ref_date','w']]\n",
    "X_train, y_train = Xy.loc[train_mask, feature_cols], Xy.loc[train_mask, 'y']\n",
    "X_valid, y_valid = Xy.loc[valid_mask, feature_cols], Xy.loc[valid_mask, 'y']\n",
    "w_train = Xy.loc[train_mask, 'w'].values\n",
    "w_valid = Xy.loc[valid_mask, 'w'].values\n",
    "\n",
    "# 평가 함수에 필요한 정보 미리 정의\n",
    "info_df = Xy.loc[valid_mask, ['영업장명_메뉴명']].reset_index(drop=True)\n",
    "info_df[['store', 'item']] = info_df['영업장명_메뉴명'].str.split('_', expand=True)\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"Optuna가 최적의 파라미터를 찾기 위해 반복적으로 호출할 함수\"\"\"\n",
    "    params = {\n",
    "        'objective': 'regression_l1',\n",
    "        'n_estimators': N_ESTIMATORS,\n",
    "        'random_state': SEED,\n",
    "        'verbose': -1,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 0.95),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 0.95),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 20, 100),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "    }\n",
    "\n",
    "    lgbm = LGBMRegressor(**params)\n",
    "    callbacks = [early_stopping(stopping_rounds=OPTUNA_EARLY_STOPPING, verbose=False)]\n",
    "\n",
    "    lgbm.fit(\n",
    "        X_train, y_train,\n",
    "        sample_weight=w_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        eval_sample_weight=[w_valid],\n",
    "        eval_metric='l1',\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    valid_pred = lgbm.predict(X_valid)\n",
    "    score = calculate_weighted_smape(y_valid.values, valid_pred, info_df)\n",
    "    return score\n",
    "\n",
    "# Optuna 스터디 생성 및 최적화 실행\n",
    "print(\"\\nStarting Optuna hyperparameter optimization...\")\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "# 최적화 결과 확인\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Optuna Optimization Finished!\")\n",
    "print(\"Best trial's Weighted SMAPE:\", study.best_value)\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "# =======================================================\n",
    "# 7. 최종 모델 학습\n",
    "# =======================================================\n",
    "print(\"Training the final model with the best hyperparameters...\")\n",
    "best_params = study.best_params\n",
    "best_params['n_estimators'] = N_ESTIMATORS\n",
    "best_params['random_state'] = SEED\n",
    "\n",
    "final_model = LGBMRegressor(**best_params)\n",
    "\n",
    "# 최종 모델 학습 시에는 Early Stopping을 더 길게 설정\n",
    "FINAL_EARLY_STOPPING = 200\n",
    "final_callbacks = [early_stopping(stopping_rounds=FINAL_EARLY_STOPPING, verbose=False)]\n",
    "final_model.fit(\n",
    "    X_train, y_train,\n",
    "    sample_weight=w_train,\n",
    "    eval_set=[(X_valid, y_valid)],\n",
    "    eval_sample_weight=[w_valid],\n",
    "    eval_metric='l1',\n",
    "    callbacks=final_callbacks\n",
    ")\n",
    "\n",
    "# 최종 모델로 검증 데이터 예측 및 평가\n",
    "valid_pred = final_model.predict(X_valid)\n",
    "score_original = smape(y_valid.values, valid_pred)\n",
    "score_weighted = calculate_weighted_smape(y_valid.values, valid_pred, info_df)\n",
    "\n",
    "print(f\"Final Valid SMAPE (Original): {score_original:.4f}\")\n",
    "print(f\"Final Valid SMAPE (Competition Weighted): {score_weighted:.6f}\\n\")\n",
    "\n",
    "\n",
    "# =======================================================\n",
    "# 8. 모델 저장 및 추론/제출\n",
    "# =======================================================\n",
    "# 모델 및 피처 정보 저장\n",
    "os.makedirs(\"lgbm_models\", exist_ok=True)\n",
    "joblib.dump(final_model, \"lgbm_models/lgbm_weighted_optuna.pkl\")\n",
    "with open(\"lgbm_models/feature_cols.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"feature_cols\": feature_cols}, f, ensure_ascii=False, indent=2)\n",
    "print(\"Final model and feature list saved.\")\n",
    "\n",
    "# 추론 및 제출 파일 생성\n",
    "print(\"Generating submission file...\")\n",
    "sample = pd.read_csv(\"sample_submission.csv\")\n",
    "all_items = list(sample.columns[1:])\n",
    "test_paths = [f\"TEST_{i:02d}.csv\" for i in range(10)]\n",
    "\n",
    "all_rows = []\n",
    "for i, tp in enumerate(test_paths):\n",
    "    tdf = pd.read_csv(tp, parse_dates=['영업일자'])\n",
    "    feats = build_test_features(tdf)\n",
    "\n",
    "    if not feats.empty:\n",
    "      # 최종 모델(final_model)을 사용하여 예측\n",
    "      preds = final_model.predict(feats[feature_cols])\n",
    "      feats['pred'] = np.maximum(0.0, preds)\n",
    "\n",
    "      for h in range(1, 8):\n",
    "          tag = f\"TEST_{i:02d}+{h}일\"\n",
    "          row = {'영업일자': tag}\n",
    "          sub = feats[feats['h']==h][['영업장명_메뉴명','pred']].set_index('영업장명_메뉴명')['pred']\n",
    "          for item in all_items:\n",
    "              row[item] = float(sub.get(item, 0.0))\n",
    "          all_rows.append(row)\n",
    "\n",
    "submission = pd.DataFrame(all_rows, columns=['영업일자'] + all_items)\n",
    "submission.to_csv(\"submission_optuna.csv\", index=False)\n",
    "print(\"\\nSubmission file created successfully -> submission_optuna.csv\")\n",
    "display(submission.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
