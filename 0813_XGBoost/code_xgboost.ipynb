{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    CUDA = torch.cuda.is_available()\n",
    "except:\n",
    "    CUDA = False\n",
    "\n",
    "print(f'CUDA available: {CUDA}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File paths are valid.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 1) 경로 설정\n",
    "# -----------------------------\n",
    "TRAIN_DIR = Path('../open/train')\n",
    "TEST_DIR  = Path('../open/test')\n",
    "SAMPLE_FP = Path('../open/sample_submission.csv')\n",
    "\n",
    "if not TRAIN_DIR.exists() or not TEST_DIR.exists() or not SAMPLE_FP.exists():\n",
    "    print('Path error: directory or file does not exist. Please check the paths.')\n",
    "    print(f'Expected file path: {TRAIN_DIR}')\n",
    "    exit()\n",
    "else:\n",
    "    print('File paths are valid.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading...\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 2) 데이터 로드\n",
    "# -----------------------------\n",
    "print('Data loading...')\n",
    "\n",
    "train = pd.read_csv('../open/train/train.csv')\n",
    "train['영업일자'] = pd.to_datetime(train['영업일자'], format='%Y-%m-%d')\n",
    "\n",
    "sample = pd.read_csv(SAMPLE_FP)\n",
    "\n",
    "tests = {}\n",
    "for i in range(10):\n",
    "    test_name = f'TEST_{i:02d}'\n",
    "    df = pd.read_csv(TEST_DIR / f'{test_name}.csv')\n",
    "    df['영업일자'] = pd.to_datetime(df['영업일자'], format='%Y-%m-%d')\n",
    "    tests[test_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering...\n",
      "Feature engineering complete\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 3) 피처 엔지니어링\n",
    "# -----------------------------\n",
    "print('Feature engineering...')\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "train['item_id'] = encoder.fit_transform(train['영업장명_메뉴명'])\n",
    "\n",
    "def make_date_feats(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_processed = dataframe.copy()\n",
    "    \n",
    "    date_column = df_processed['영업일자']\n",
    "    df_processed['year']    = date_column.dt.year\n",
    "    df_processed['month']   = date_column.dt.month\n",
    "    df_processed['day']     = date_column.dt.day\n",
    "    df_processed['weekday'] = date_column.dt.weekday\n",
    "    \n",
    "    df_processed['is_weekend'] = df_processed['weekday'].apply(lambda x: 1 if x in [5, 6] else 0)\n",
    "    \n",
    "    df_processed['month_sin'] = np.sin(2 * np.pi * df_processed['month'] / 12)\n",
    "    df_processed['month_cos'] = np.cos(2 * np.pi * df_processed['month'] / 12)\n",
    "    df_processed['wday_sin']  = np.sin(2 * np.pi * df_processed['weekday'] / 7)\n",
    "    df_processed['wday_cos']  = np.cos(2 * np.pi * df_processed['weekday'] / 7)\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "train = make_date_feats(train)\n",
    "train.sort_values(['item_id', '영업일자'], inplace=True)\n",
    "\n",
    "lags = [1, 7, 14]\n",
    "for lag in lags:\n",
    "    train[f'lag_{lag}'] = train.groupby('item_id', observed=True)['매출수량'].shift(lag)\n",
    "\n",
    "groups = train.groupby('item_id', observed=True)['매출수량']\n",
    "train['rolling_mean_7']     = groups.shift(1).rolling(7).mean().reset_index(0, drop=True)\n",
    "train['rolling_mean_14']    = groups.shift(1).rolling(14).mean().reset_index(0, drop=True)\n",
    "train['rolling_std_7']      = groups.shift(1).rolling(7).std().reset_index(0, drop=True)\n",
    "\n",
    "cols_with_na = [\n",
    "    'lag_1', 'lag_7', 'lag_14', 'rolling_mean_7', 'rolling_mean_14', 'rolling_std_7'\n",
    "]\n",
    "train.dropna(subset=cols_with_na, inplace=True)\n",
    "\n",
    "feature_cols = [\n",
    "    'year',\n",
    "    'month',\n",
    "    'day',\n",
    "    'weekday',\n",
    "    'is_weekend',\n",
    "    'month_sin',\n",
    "    'month_cos',\n",
    "    'wday_sin',\n",
    "    'wday_cos',\n",
    "    'item_id',\n",
    "    'lag_1',\n",
    "    'lag_7',\n",
    "    'lag_14',\n",
    "    'rolling_mean_7',\n",
    "    'rolling_mean_14',\n",
    "    'rolling_std_7',\n",
    "]\n",
    "X = train[feature_cols]\n",
    "y = train['매출수량'].astype(float)\n",
    "\n",
    "XGBparams = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'tree_method': 'hist',\n",
    "    'device': 'cuda' if CUDA else 'cpu',\n",
    "    'max_depth': 8,\n",
    "    'learning_rate': 0.05,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'seed': 42,\n",
    "}\n",
    "\n",
    "print('Feature engineering complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best iteration using TimeSeriesSplit CV...\n",
      "[0]\tval-rmse:10.62126\n",
      "[145]\tval-rmse:7.58975\n",
      "[0]\tval-rmse:9.47710\n",
      "[179]\tval-rmse:7.05368\n",
      "[0]\tval-rmse:19.88510\n",
      "[155]\tval-rmse:16.71569\n",
      "[0]\tval-rmse:37.42719\n",
      "[180]\tval-rmse:29.87412\n",
      "[0]\tval-rmse:87.11863\n",
      "[200]\tval-rmse:59.36537\n",
      "[212]\tval-rmse:59.34093\n",
      "Best iteration: 79\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 4) TimeSeriesSplit CV로 best_iteration 찾기\n",
    "# -----------------------------\n",
    "print('Finding best iteration using TimeSeriesSplit CV...')\n",
    "\n",
    "time_series_validator = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "optimal_iterations_list = []\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(time_series_validator.split(X), 1):\n",
    "    X_tf, X_val = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "    y_tf, y_val = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "\n",
    "    dtr = xgb.DMatrix(X_tf, label=y_tf)\n",
    "    dva = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "    trained_model = xgb.train(\n",
    "        XGBparams,\n",
    "        dtr,\n",
    "        num_boost_round=5000,\n",
    "        evals=[(dva, 'val')],\n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=200,\n",
    "    )\n",
    "    optimal_iterations_list.append(trained_model.best_iteration)\n",
    "\n",
    "if len(optimal_iterations_list) > 0:\n",
    "    final_boost_round = int(np.median(optimal_iterations_list))\n",
    "else:\n",
    "    final_boost_round = 1000\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(X, label=y)\n",
    "final_model = xgb.train(\n",
    "    XGBparams, \n",
    "    data_dmatrix, \n",
    "    num_boost_round=final_boost_round, \n",
    "    verbose_eval=False\n",
    ")\n",
    "\n",
    "print(f'Best iteration: {final_boost_round}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recursive prediction...\n",
      "Prediction complete\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 5) 재귀 예측\n",
    "# -----------------------------\n",
    "print('Recursive prediction...')\n",
    "prediction_results = []\n",
    "\n",
    "for test_name, current_test_data in tests.items():\n",
    "    current_test_data = current_test_data.copy()\n",
    "    current_test_data['item_id'] = encoder.transform(current_test_data['영업장명_메뉴명'])\n",
    "    current_test_data = make_date_feats(current_test_data)\n",
    "    current_test_data = current_test_data.sort_values(['item_id', '영업일자'])\n",
    "\n",
    "    last_date = current_test_data['영업일자'].max()\n",
    "    items = current_test_data['영업장명_메뉴명'].unique()\n",
    "\n",
    "    history = current_test_data[['영업일자', 'item_id', '영업장명_메뉴명', '매출수량']].copy()\n",
    "\n",
    "    preds_rows = []\n",
    "    current_date = last_date\n",
    "    for step in range(1, 8):\n",
    "        target_date = current_date + pd.Timedelta(days=1)\n",
    "\n",
    "        # 예측을 위한 데이터 프레임 생성\n",
    "        frame = pd.DataFrame(\n",
    "            {'영업일자': np.repeat(target_date, len(items)), '영업장명_메뉴명': items}\n",
    "        )\n",
    "        frame['item_id'] = encoder.transform(frame['영업장명_메뉴명'])\n",
    "        frame = make_date_feats(frame)\n",
    "\n",
    "        # 특징 계산\n",
    "        temp = history.copy()\n",
    "        for lag in [1, 7, 14]:\n",
    "            lagged = temp[['영업일자', 'item_id', '매출수량']].copy()\n",
    "            lagged['영업일자'] = lagged['영업일자'] + pd.Timedelta(days=lag)\n",
    "            frame = frame.merge(\n",
    "                lagged.rename(columns={'매출수량': f'lag_{lag}'}),\n",
    "                on=['영업일자', 'item_id'],\n",
    "                how='left',\n",
    "            )\n",
    "\n",
    "        roll_base = history.sort_values(['item_id', '영업일자']).copy()\n",
    "        gb = roll_base.groupby('item_id', observed=True)['매출수량']\n",
    "        roll_base['rolling_mean_7']    = gb.rolling(7).mean().reset_index(0, drop=True)\n",
    "        roll_base['rolling_mean_14']   = gb.rolling(14).mean().reset_index(0, drop=True)\n",
    "        roll_base['rolling_std_7']     = gb.rolling(7).std().reset_index(0, drop=True)\n",
    "        roll_base['영업일자']           = roll_base['영업일자'] + pd.Timedelta(days=1)\n",
    "\n",
    "        frame = frame.merge(\n",
    "            roll_base[\n",
    "                ['영업일자', 'item_id', 'rolling_mean_7', 'rolling_mean_14', 'rolling_std_7']\n",
    "            ],\n",
    "            on=['영업일자', 'item_id'],\n",
    "            how='left',\n",
    "        )\n",
    "\n",
    "        fill_cols = ['lag_1', 'lag_7', 'lag_14', 'rolling_mean_7', 'rolling_mean_14', 'rolling_std_7']\n",
    "        frame[fill_cols] = frame[fill_cols].fillna(0)\n",
    "\n",
    "        X_pred           = frame[feature_cols]\n",
    "        dpred            = xgb.DMatrix(X_pred)\n",
    "        predicted_values = final_model.predict(dpred)\n",
    "        predicted_values = np.maximum(predicted_values, 0)\n",
    "        frame['pred']    = predicted_values\n",
    "\n",
    "        # 이전 예측 결과를 history에 추가해 재귀\n",
    "        add_hist = frame[['영업일자', 'item_id', '영업장명_메뉴명', 'pred']].rename(\n",
    "            columns={'pred': '매출수량'}\n",
    "        )\n",
    "        history = pd.concat([history, add_hist], ignore_index=True)\n",
    "\n",
    "        # 결과 저장\n",
    "        frame_out = frame[['영업일자', '영업장명_메뉴명', 'pred']].copy()\n",
    "        frame_out['영업일자'] = f'{test_name}+{step}일'\n",
    "        preds_rows.append(frame_out)\n",
    "\n",
    "        current_date = target_date\n",
    "\n",
    "    test_pred = pd.concat(preds_rows, ignore_index=True)\n",
    "    wide = test_pred.pivot(index='영업일자', columns='영업장명_메뉴명', values='pred')\n",
    "    prediction_results.append(wide)\n",
    "\n",
    "print('Prediction complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created: ../open/out/submission_xgboost_1.csv\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 7) 최종 제출 파일 생성\n",
    "# -----------------------------\n",
    "submission = pd.concat(prediction_results)\n",
    "submission = submission.reset_index().rename(columns={'index': '영업일자'})\n",
    "submission = submission[sample.columns]\n",
    "out_path = '../open/out/submission_xgboost_1.csv'\n",
    "submission.to_csv(out_path, index=False, encoding='utf-8-sig')\n",
    "print(f'Submission file created: {out_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
